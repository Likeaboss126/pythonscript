# init_vector_db.py
import pandas as pd
import psycopg2
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.document_loaders import DataFrameLoader
from langchain_community.vectorstores import Chroma

# --- 1. Connect to PostgreSQL ---
conn = psycopg2.connect(
    dbname="your_dbname",
    user="your_user",
    password="your_password",
    host="your_host",
    port="5432"
)

query = """
SELECT Functionality, DateTime, API, Total, Passed, Failed, AverageTimeTaken
FROM data;
"""
df = pd.read_sql(query, conn)
conn.close()

# --- 2. Convert each record into text for embedding ---
df["text"] = df.apply(
    lambda r: (
        f"On {r.DateTime}, Functionality '{r.Functionality}' had API '{r.API}' "
        f"with {r.Total} total calls, {r.Passed} passed, {r.Failed} failed, "
        f"and an average response time of {r.AverageTimeTaken} ms."
    ),
    axis=1
)

# --- 3. Load DataFrame into LangChain Documents ---
loader = DataFrameLoader(df, page_content_column="text")
docs = loader.load()

# --- 4. Create embeddings and save to Chroma (persistent) ---
embeddings = OllamaEmbeddings(model="nomic-embed-text")

vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embeddings,
    persist_directory="./api_perf_chroma"
)
vectorstore.persist()
print("âœ… Vector DB created and stored at ./api_perf_chroma")
