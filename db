import ollama
import json
import streamlit as st

st.subheader("ðŸ’¬ AI Assistant: Ask About Performance Trends")

# Prepare context data (limit rows to avoid overloading)
context_data = df_filtered.head(100).to_dict(orient='records')

user_question = st.text_input("Ask a question about your API performance:")

if st.button("Ask AI") and user_question:
    with st.spinner("Analyzing data..."):
        # Prepare prompt for Ollama
        prompt = f"""
        You are an API performance analyst.
        Analyze this dataset (in JSON) and answer questions about trends, failures, and performance.
        Data:
        {json.dumps(context_data, indent=2)}

        Question: {user_question}
        Provide your answer clearly in plain English, highlighting insights.
        """

        try:
            response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])
            st.markdown(f"**AI Insight:** {response['message']['content']}")
        except Exception as e:
            st.error(f"Error connecting to Ollama: {e}")
