import chromadb
from ollama import Client, chat, ChatResponse
import random
import time
from datetime import datetime, timedelta
import json
from typing import Optional, Dict, Any, List
from typing import Literal # Used for cleaner type hinting

COLLECTION_NAME = "api_performance_v5"
DB_PATH = "./chroma_db_performance_v5"
OLLAMA_HOST = 'http://localhost:11434'
OLLAMA_MODEL = 'llama3.1'  # Use your specific Llama 3 model tag
NUM_RECORDS = 5000
API_LIST = ["POST /login", "GET /userProfile", "POST /submitOrder", "GET /productDetails"]
FUNCTIONALITY_LIST = ["Authentication", "UserManagement", "OrderProcessing", "Catalog"]
RelativePeriod = Literal['TODAY', 'YESTERDAY', 'LAST_7_DAYS', 'LAST_30_DAYS', 'LAST_MONTH']
ollama_client = Client(host=OLLAMA_HOST)


def handle_user_query_ollama(user_query: str):
    messages = [
        {"role": "system",
         "content": "You are an expert performance analysis RAG agent. You must use the 'build_chroma_filter' tool. "
    "Crucially, if the user specifies a relative time period (e.g., 'today', 'yesterday', 'last week'), "
    "you MUST calculate the date in this format YYYY-MM-DDTHH:MM:SS for  'period_start' and 'period_end' arguments "
                    "Do not Add API filter if user has not provided any API in query"
    "For instance, 'yesterday' should be calculated as yesterday's start time and yesterday's end time. "
    "For instance, 'today' should be calculated as today's start time and today's end time. "
    "If no end time is specified (e.g., 'since last Monday'), only populate 'period_start'. "
    "DO NOT answer the question directly; provide the tool call only." 
                    "If the query is a specific trend comparison (e.g., 'compare this month to last month'), "
                    "note that you will need to run the analysis in a separate step, "
                    "but try to parse the primary filter for the API/time frame first. "
                    "For 'analyze today's stats', use a filter that captures all runs today with failed > 0 OR averagetimetaken > 3000ms."},
        {"role": "user", "content": user_query},
    ]

    # Initial LLM call to decide on tool use
    response: ChatResponse = ollama_client.chat(
        model=OLLAMA_MODEL,
        messages=messages,
        tools=[build_chroma_filter],
        # Llama 3 models are generally very good at tool calling
    )

def build_chroma_filter(
        api: Optional[str] = None,
        functionality: Optional[str] = None,
        failed_op: Optional[str] = None,
        failed_val: Optional[int] = None,
        time_op: Optional[str] = None,
        time_val: Optional[float] = None,
        period_start: Optional[str] = None,
        period_end: Optional[str] = None,
        period_type: Optional[RelativePeriod] = None, # Expects one of the literal values
) -> str:
    """
    Analyzes user intent and builds a ChromaDB filter dictionary for the 'where' clause.

    Args:
        api: The specific API endpoint name (e.g., 'POST /login').
        functionality: The high-level functionality (e.g., 'OrderProcessing').
        failed_op: The comparison operator for failures ('$gt', '$lt', '$eq').
        failed_val: The numerical value for the failures' comparison.
        time_op: The comparison operator for averagetimetaken ('$gt', '$lt', '$eq').
        time_val: The numerical value (in ms) for the time comparison.
        period_start: The start date of the period as an ISO 8601 string (YYYY-MM-DDTHH:MM:SS).
        period_end: The end date of the period as an ISO 8601 string (YYYY-MM-DDTHH:MM:SS).
        period_type: The relative time period specified by the user ('TODAY', 'YESTERDAY', 'LAST_7_DAYS', etc.).
    Returns:
        A JSON string of the structured ChromaDB filter.
    """

    # This function is not executed directly by the LLM. It's the schema the LLM uses.
    # The actual filter creation happens within the Python code after the LLM call.
    return json.dumps({
        "api": api, "functionality": functionality,
        "failed_op": failed_op, "failed_val": failed_val,
        "time_op": time_op, "time_val": time_val,
        "period_start": period_start, "period_end": period_end,
        "period_type": period_type
    })



if __name__ == "__main__":

    # A. Index the data first
    print("\n" + "=" * 80)
    print(f"DEMONSTRATING QUERIES VIA OLLAMA ({OLLAMA_MODEL}) FUNCTION CALLING")
    print("=" * 80)

    # 1. SPECIFIC FILTER QUERY (Handled via tool call and single search)
    handle_user_query_ollama("APIs with more than 2000 milli seconds response time and more than 25 failures on 25th September 2025")
    # handle_user_query_ollama("pl
