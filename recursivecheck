import requests
import time
import urllib3
from urllib.parse import quote_plus

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

BASE_URL = "https://<domain>.atlassian.net/wiki"
TOKEN = "YOUR_BEARER_TOKEN"
SPACE_KEY = "ABCD"
PARENT_TITLE = "Data Issues"

headers = {
    "Accept": "application/json",
    "Authorization": f"Bearer {TOKEN}"
}

# ---------- Safe GET with backoff ----------
def safe_get(url, max_retries=4):
    wait_time = 5

    for attempt in range(max_retries):
        r = requests.get(url, headers=headers, verify=False)

        if r.status_code == 429:
            retry_after = int(r.headers.get("Retry-After", wait_time))
            print(f"â³ Rate limited. Sleeping {retry_after}s")
            time.sleep(retry_after)
            wait_time *= 2
            continue

        r.raise_for_status()
        return r.json()

    raise Exception("âŒ Max retries exceeded due to rate limiting")

# ---------- 1ï¸âƒ£ Get parent page ID by title ----------
def get_parent_page_id():
    encoded_title = quote_plus(PARENT_TITLE)

    url = (
        f"{BASE_URL}/rest/api/content"
        f"?spaceKey={SPACE_KEY}&title={encoded_title}&limit=1"
    )

    data = safe_get(url)

    if data["size"] == 0:
        raise Exception("âŒ Parent page not found")

    parent_id = data["results"][0]["id"]
    print(f"ğŸ“„ Parent ID: {parent_id}")
    return parent_id

# ---------- 2ï¸âƒ£ Paginate space and collect children ----------
def find_children(parent_id):
    children = []
    start = 0
    limit = 25

    while True:
        url = (
            f"{BASE_URL}/rest/api/content"
            f"?spaceKey={SPACE_KEY}&limit={limit}&start={start}&expand=ancestors"
        )

        data = safe_get(url)

        for page in data["results"]:
            if page.get("ancestors"):
                # last ancestor = direct parent
                if page["ancestors"][-1]["id"] == parent_id:
                    children.append({
                        "id": page["id"],
                        "title": page["title"]
                    })

        # Stop early if children found and no need to scan full space
        if children:
            break

        if "next" not in data["_links"]:
            break

        start += limit
        time.sleep(2)  # prevent rate burst

    return children

# ---------- MAIN ----------
if __name__ == "__main__":
    print("ğŸ” Finding parent...")
    parent_id = get_parent_page_id()

    print("ğŸ” Scanning space for children (cheap)...")
    children = find_children(parent_id)

    print("\nğŸ“‚ Child pages found:")
    for c in children:
        print(f"{c['id']} â†’ {c['title']}")

    if not children:
        print("âš ï¸ No children found in scanned pages")

    print("\nâœ… POC complete (no heavy API calls)")
